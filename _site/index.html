<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>
  
  Nikhil Prakash
  
  
</title>
<meta name="description" content="Nikhil Prakash's Academic Website
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
  rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css"
  integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"
  integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css"
  href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet"
  href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon"
  href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üéØ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>

  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/" target="_blank">
                cv
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/" target="">
                publications
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
      <span class="font-weight-bold">Nikhil</span>  Prakash
    </h1>
    <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      <div class="profile-image-container">
        <img class="img-fluid rounded profile-pic" src="/assets/img/profile_pic.png" srcset="/assets/img/profile_pic.png 323w">
        <img class="img-fluid rounded profile-pic-hover" src="/assets/img/profile_pic_old.jpg" srcset="/assets/img/profile_pic_old.jpg 323w">
      </div>
      
      <div class="address">
        <p>22nd floor, 177 Huntington Ave</p> <p>Boston, MA 02115</p>

      </div>
      
    </div>
    

    <div class="clearfix">
      <p>I‚Äôm a forth year Ph.D. student at <a href="https://www.northeastern.edu/" target="_blank" rel="noopener noreferrer">Northeastern University</a>, advised by <a href="https://baulab.info/" target="_blank" rel="noopener noreferrer">Prof. David Bau</a>. I completed my Bachelor of Engineering from <a href="https://rvce.edu.in/" target="_blank" rel="noopener noreferrer">RV College of Engineering, Bangalore, India</a> in fall 2020, with a focus on electrical and computer science.</p>

<p>Last summer, I‚Äôm interned at Apple in the <a href="https://vis.aiml.apple.com" target="_blank" rel="noopener noreferrer">AIML Visualization</a> team to work on mechanistic interpretability of math reasoining in LLMs. Previously, I‚Äôve interned at <a href="https://prair.group/" target="_blank" rel="noopener noreferrer">Practical AI Alignment and Interpretability Research Group</a> with <a href="https://atticusg.github.io/" target="_blank" rel="noopener noreferrer">Dr. Atticus Geiger</a> and <a href="https://www.matsprogram.org" target="_blank" rel="noopener noreferrer">SERI-MATS</a> (first phrase) with <a href="https://www.neelnanda.io/about" target="_blank" rel="noopener noreferrer">Neel Nanda</a>. Prior to that, I worked as a visiting scholar at the <a href="https://asiabiega.github.io/" target="_blank" rel="noopener noreferrer">Max Planck Institute for Security and Privacy</a>, and had stints at <a href="https://www.kixlab.org/" target="_blank" rel="noopener noreferrer">Korea Advanced Institute of Science &amp; Technology</a> and <a href="https://cse.iitrpr.ac.in/" target="_blank" rel="noopener noreferrer">Indian Institute of Technology Ropar</a>.</p>

<p>Broadly, my interest lies in understanding the internal mechanisms of deep neural networks to enhance human-AI collaboration and prevent misalignment. Currently, I‚Äôm investigating cognitive abilities such as reasoning and theory of mind in large language models.</p>

<p>I have received invaluable support from many people throughout my career, and as a result, I‚Äôm always happy to assist others and share insights from my experiences. Please feel free to reach out.</p>

    </div>

    
    <div class="news">
  <h2>news</h2>
  
  <div class="news-scrollable">
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
        
        
        <tr>
          <th>Oct, 2025</th>
          <td>
            
            Invited to give a talk at Boston University NLP Group.

            
          </td>
        </tr>
        
        <tr>
          <th>Oct, 2025</th>
          <td>
            
            Excited to attend COLM 2025 in Montreal!

            
          </td>
        </tr>
        
        <tr>
          <th>Sep, 2025</th>
          <td>
            
            Gave a talk in Algorithms and Behavioral Science Coffee Seminar hosted by MIT Economics.

            
          </td>
        </tr>
        
        <tr>
          <th>Aug, 2025</th>
          <td>
            
            Attended and presented my work at the 2nd New England Mechanistic Interpretability (NEMI) workshop.

            
          </td>
        </tr>
        
        <tr>
          <th>Aug, 2025</th>
          <td>
            
            <a class="news-title" href="/news/apple_intern_end/">Last day of Apple Internship at Apple Park!</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Jun, 2025</th>
          <td>
            
            Invited to give a talk at <a href="https://app.ploutos.dev/streams/flat-waxbill" target="_blank" rel="noopener noreferrer">ploutos.dev</a> on our recent belief tracking paper.

            
          </td>
        </tr>
        
        <tr>
          <th>May, 2025</th>
          <td>
            
            Started my Apple internship with the AIML Visualization team!

            
          </td>
        </tr>
        
        <tr>
          <th>Apr, 2025</th>
          <td>
            
            Oral Presentation of our recent work on Belief Tracking Mechanism in LMs at <a href="https://nenlp.github.io/spr2025/" target="_blank" rel="noopener noreferrer">New England NLP 2025</a>.

            
          </td>
        </tr>
        
        <tr>
          <th>Mar, 2025</th>
          <td>
            
            Reviewing for ICML 2025, COLM 2025, TMLR.

            
          </td>
        </tr>
        
        <tr>
          <th>Mar, 2025</th>
          <td>
            
            <a class="news-title" href="/news/candidacy/">PhD Candidacy Achieved!</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Mar, 2025</th>
          <td>
            
            Accepted research internship offer from Apple.

            
          </td>
        </tr>
        
        <tr>
          <th>Jan, 2025</th>
          <td>
            
            Our paper <a href="https://arxiv.org/abs/2407.14561" target="_blank" rel="noopener noreferrer">NNsight and NDIF: Democratizing Access to Foundation Model Internals</a> got accepted to ICLR 2025! <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">

            
          </td>
        </tr>
        
        <tr>
          <th>Nov, 2024</th>
          <td>
            
            Received a complimentary NeurIPS 2024 registration for my service as a reviewer.

            
          </td>
        </tr>
        
        <tr>
          <th>Aug, 2024</th>
          <td>
            
            Reviewing for ICLR 2025.

            
          </td>
        </tr>
        
        <tr>
          <th>Jul, 2024</th>
          <td>
            
            Our paper <a href="https://arxiv.org/abs/2407.14561" target="_blank" rel="noopener noreferrer">NNsight and NDIF: Democratizing Access to Foundation Model Internals</a> is on ArXiv!

            
          </td>
        </tr>
        
        <tr>
          <th>Jul, 2024</th>
          <td>
            
            Interning at <a href="https://prair.group" target="_blank" rel="noopener noreferrer">Practical AI Alignment and Interpretability Research Group</a> with <a href="https://atticusg.github.io" target="_blank" rel="noopener noreferrer">Dr. Atticus Geiger</a>.

            
          </td>
        </tr>
        
        <tr>
          <th>Jun, 2024</th>
          <td>
            
            Reviewing for NeurIPS 2024 (main conference and workshop proposals).

            
          </td>
        </tr>
        
        <tr>
          <th>May, 2024</th>
          <td>
            
            Invited talk at <a href="https://prair.group/" target="_blank" rel="noopener noreferrer">Practical AI Alignment and Interpretability Research Group</a>.

            
          </td>
        </tr>
        
        <tr>
          <th>May, 2024</th>
          <td>
            
            Invited talk at <a href="https://labs.iitgn.ac.in/lingo" target="_blank" rel="noopener noreferrer">Computational Linguistics and Complex Social Networks</a> in Indian Institute of Technology Gandhinagar.

            
          </td>
        </tr>
        
        <tr>
          <th>May, 2024</th>
          <td>
            
            Attending ICLR 2024 at Vienna in-person <img class="emoji" title=":beach_umbrella:" alt=":beach_umbrella:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3d6.png" height="20" width="20">!

            
          </td>
        </tr>
        
        <tr>
          <th>Apr, 2024</th>
          <td>
            
            Invited talk at <a href="https://nenlp.github.io/spr2024/index.html" target="_blank" rel="noopener noreferrer">New England NLP 2024</a>.

            
          </td>
        </tr>
        
        <tr>
          <th>Apr, 2024</th>
          <td>
            
            Co-organizing <a href="https://iclr.cc/virtual/2024/social/22279" target="_blank" rel="noopener noreferrer">Mechanistic Interpretability Social</a> at ICLR 2024 with Gabriele Sarti.

            
          </td>
        </tr>
        
        <tr>
          <th>Apr, 2024</th>
          <td>
            
            <a class="news-title" href="/news/gemma/">Awarded Google's Gemma Academic Program <img class="emoji" title=":trophy:" alt=":trophy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c6.png" height="20" width="20">.</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Jan, 2024</th>
          <td>
            
            Our paper ‚ÄúFine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking‚Äù got accepted at ICLR 2024!

            
          </td>
        </tr>
        
        <tr>
          <th>Oct, 2023</th>
          <td>
            
            Served as a reviewer for ATTRIB 2023 workshop @ NeurIPS.

            
          </td>
        </tr>
        
        <tr>
          <th>Jul, 2023</th>
          <td>
            
            Our short paper got accepted at Challenges of Deploying Generative AI workshop at ICML 2023!

            
          </td>
        </tr>
        
        <tr>
          <th>Jul, 2023</th>
          <td>
            
            <a class="news-title" href="/news/seri-mats/">Participated in Stanford Existential Risks Initiative ML Alignment Theory Scholars (SERI-MATS) 2023.</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Jun, 2023</th>
          <td>
            
            <a class="news-title" href="/news/arena/">Participated in Alignment Research Engineer Accelerator (ARENA) 2023.</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Feb, 2023</th>
          <td>
            
            <a class="news-title" href="/news/IUI23/">Our paper got acceptetd at IUI 23!</a>
            
          </td>
        </tr>
        
        <tr>
          <th>Sep, 2022</th>
          <td>
            
            <img class="emoji" title=":innocent:" alt=":innocent:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f607.png" height="20" width="20"> Started my Ph.D. at Northeastern with Prof. David Bau!

            
          </td>
        </tr>
        
      </table>
    </div>
  </div>
  
</div>
    

    
    <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div class="col-sm-3"><img class="img-fluid" src="/assets/img/causalmodel_novis.png" alt=""></div>

  <div id="prakash2025languagemodelsuselookbacks" class="col-sm-8">
    
    <div class="title">Language Models use Lookbacks to Track Beliefs</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Prakash, Nikhil</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Shapira, Natalie,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Sharma, Arnab Sen,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Riedl, Christoph,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Belinkov, Yonatan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Shaham, Tamar Rott,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Bau, David,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Geiger, Atticus
      
      
      
      
      
    </div>

    <div class="periodical">
      
      
      
      2025
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2505.14685" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
      
      
      <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      <a href="https://belief.baulab.info/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>How do language models (LMs) represent characters‚Äô beliefs, especially when those beliefs may differ from reality? This question lies at the heart of understanding the Theory of Mind (ToM) capabilities of LMs. We analyze Llama-3-70B-Instruct‚Äôs ability to reason about characters‚Äô beliefs using causal mediation and abstraction. We construct a dataset that consists of simple stories where two characters each separately change the state of two objects, potentially unaware of each other‚Äôs actions. Our investigation uncovered a pervasive algorithmic pattern that we call a lookback mechanism, which enables the LM to recall important information when it becomes necessary. The LM binds each character-object-state triple together by co-locating reference information about them, represented as their Ordering IDs (OIs) in low rank subspaces of the state token‚Äôs residual stream. When asked about a character‚Äôs beliefs regarding the state of an object, the binding lookback retrieves the corresponding state OI and then an answer lookback retrieves the state token. When we introduce text specifying that one character is (not) visible to the other, we find that the LM first generates a visibility ID encoding the relation between the observing and the observed character OIs. In a visibility lookback, this ID is used to retrieve information about the observed character and update the observing character‚Äôs beliefs. Our work provides insights into the LM‚Äôs belief tracking mechanisms, taking a step toward reverse-engineering ToM reasoning in LMs.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">prakash2025languagemodelsuselookbacks</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{Language Models use Lookbacks to Track Beliefs}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Nikhil Prakash and Natalie Shapira and Arnab Sen Sharma and Christoph Riedl and Yonatan Belinkov and Tamar Rott Shaham and David Bau and Atticus Geiger}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2505.14685}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.CL}</span><span class="p">,</span>
      <span class="na">url</span><span class="p">=</span><span class="s">{https://arxiv.org/abs/2505.14685}</span><span class="p">,</span> 
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div> -->

  <div class="col-sm-3"><img class="img-fluid" src="/assets/img/iclr24.png" alt="ICLR"></div>

  <div id="prakash2024finetuning" class="col-sm-8">
    
    <div class="title">Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Prakash, Nikhil</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Shaham, Tamar Rott,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Haklay, Tal,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Belinkov, Yonatan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Bau, David
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In International Conference on Learning Representations (ICLR)</em>
      
      
      
      2024
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2402.14811" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
      
      
      <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      <a href="https://finetuning.baulab.info/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fine-tuning on generalized tasks such as instruction following, code generation, and mathematics has been shown to enhance language models‚Äô performance on a range of tasks. Nevertheless, explanations of how such fine-tuning influences the internal computations in these models remain elusive. We study how fine-tuning affects the internal mechanisms implemented in language models. As a case study, we explore the property of entity tracking, a crucial facet of language comprehension, where models fine-tuned on mathematics have substantial performance gains. We identify a mechanism that enables entity tracking and show that (i) both the original model and its fine-tuned version implement entity tracking with the same circuit. In fact, the entity tracking circuit of the fine-tuned version performs better than the full original model. (ii) The circuits of all the models implement roughly the same functionality, that is entity tracking is performed by tracking the position of the correct entity in both the original model and its fine-tuned version. (iii) Performance boost in the fine-tuned model is primarily attributed to its improved ability to handle positional information. To uncover these findings, we employ two methods: DCM, which automatically detects model components responsible for specific semantics, and CMAP, a new approach for patching activations across models to reveal improved mechanisms. Our findings suggest that fine-tuning enhances, rather than fundamentally alters, the mechanistic operation of the model.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">prakash2024finetuning</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Prakash, Nikhil and Shaham, Tamar Rott and Haklay, Tal and Belinkov, Yonatan and Bau, David}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proceedings of the 2024 International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">note</span><span class="p">=</span><span class="s">{arXiv:2402.14811}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div> -->

  <div class="col-sm-3"><img class="img-fluid" src="/assets/img/icml23.png" alt="ICML"></div>

  <div id="davies2023discovering" class="col-sm-8">
    
    <div class="title">Discovering Variable Binding Circuitry with Desiderata</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Davies, Xander,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Nadeau, Max,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Prakash, Nikhil</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Shaham, Tamar Rott,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Bau, David
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Challenges in Deployable Generative AI Workshop, International Conference on Machine Learning (ICML)</em>
      
      
      
      2023
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      <a href="http://arxiv.org/abs/2307.03637" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
      
      
      <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      <a href="https://dcm.baulab.info/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent work has shown that computation in language models may be human-understandable, with successful efforts to localize and intervene on both single-unit features and input-output circuits. Here, we introduce an approach which extends causal mediation experiments to automatically identify model components responsible for performing a specific subtask by solely specifying a set of \textitdesiderata, or causal attributes of the model components executing that subtask. As a proof of concept, we apply our method to automatically discover shared \textitvariable binding circuitry in LLaMA-13B, which retrieves variable values for multiple arithmetic tasks. Our method successfully localizes variable binding to only 9 attention heads (of the 1.6k) and one MLP in the final token‚Äôs residual stream.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">davies2023discovering</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Discovering Variable Binding Circuitry with Desiderata}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Davies, Xander and Max Nadeau and Nikhil Prakash and Tamar Rott Shaham and David Bau}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2307.03637}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div></li>
</ol>
</div>
    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%70%72%61%6B%61%73%68.%6E%69%6B@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://twitter.com/nikhil07prakash" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
<a href="https://www.semanticscholar.org/author/Nikhil-Prakash/2284985448" title="Semantic Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i></a>
<a href="https://scholar.google.com/citations?user=kUfq-fEAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>



<a href="https://github.com/nix07" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/nikhil07prakash" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>












      </div>
      <div class="contact-note">Please email me to get a quick response.
</div>
    </div>
    
  </article>

</div>

<style>
  /* CSS for the profile image hover effect */
  .profile-image-container {
    position: relative;
    display: inline-block;
  }
  
  .profile-pic, .profile-pic-hover {
    display: block;
    width: 100%;
    transition: opacity 0.3s ease;
  }
  
  .profile-pic-hover {
    position: absolute;
    top: 0;
    left: 0;
    opacity: 0;
  }
  
  .profile-image-container:hover .profile-pic {
    opacity: 0;
  }
  
  .profile-image-container:hover .profile-pic-hover {
    opacity: 1;
  }
</style>
    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    ¬© Copyright 2025 Nikhil  Prakash.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-185703812-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-185703812-1');
</script>






</html>
